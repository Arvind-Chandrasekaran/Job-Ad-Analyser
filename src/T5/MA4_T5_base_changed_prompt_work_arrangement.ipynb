{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBQQF1ON3Sj3",
        "outputId": "8015f964-f420-41d4-8993-fac9663e5a07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sentencepiece\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "# Use GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Choose model\n",
        "model_name = 'google/flan-t5-base'\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name).to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPbA8nN84jGN",
        "outputId": "80a872a4-0c9e-4f31-81ec-790f82fad4f9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "\n",
        "import time\n",
        "\n",
        "job_ad = \"We are looking for a software developer to join our team in our downtown office in New York. Must be available to work in person 5 days a week.\"\n",
        "\n",
        "# Format the prompt\n",
        "\n",
        "prompt = f\"Classify the work arrangement of the following job ad: {job_ad}\"\n",
        "\n",
        "start_time = time.time()\n",
        "# Tokenize\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='pt', truncation=True).to(device) # Move input_ids to the same device as the model\n",
        "\n",
        "# Generate output\n",
        "job_ids = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
        "\n",
        "stop_time = time.time()\n",
        "execution_time = stop_time - start_time\n",
        "print(\"Execution time:\", execution_time, \"seconds\")\n",
        "\n",
        "# Decode and print\n",
        "print(\"Summary:\", tokenizer.decode(job_ids[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlpuvSX-4sIP",
        "outputId": "cdc033a2-5151-4b6d-c09d-e69f2ffe6ea8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution time: 0.18985843658447266 seconds\n",
            "Summary: in person\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "folder_path = '/content/drive/MyDrive/AB_job_data_files'\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# find location of different files:\n",
        "file_location = {}\n",
        "# Check if the folder exists\n",
        "if os.path.exists(folder_path):\n",
        "  os.chdir(folder_path)\n",
        "  for num, f in enumerate(os.listdir()):\n",
        "    file_location[f] = os.path.join(folder_path, f)\n",
        "\n",
        "else:\n",
        "  print(f\"Folder not found: {folder_path}\")\n",
        "\n",
        "print(file_location)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jlwc52C7OmS",
        "outputId": "ac62b3f8-e1f1-44b6-c95b-0ac637854e48"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "{'seniority_labelled_test_set.csv': '/content/drive/MyDrive/AB_job_data_files/seniority_labelled_test_set.csv', 'unlabelled_development_set.csv': '/content/drive/MyDrive/AB_job_data_files/unlabelled_development_set.csv', 'salary_labelled_development_set.csv': '/content/drive/MyDrive/AB_job_data_files/salary_labelled_development_set.csv', 'seniority_labelled_development_set.csv': '/content/drive/MyDrive/AB_job_data_files/seniority_labelled_development_set.csv', 'work_arrangements_test_set.csv': '/content/drive/MyDrive/AB_job_data_files/work_arrangements_test_set.csv', 'salary_labelled_test_set.csv': '/content/drive/MyDrive/AB_job_data_files/salary_labelled_test_set.csv', 'work_arrangements_development_set.csv': '/content/drive/MyDrive/AB_job_data_files/work_arrangements_development_set.csv', 'results': '/content/drive/MyDrive/AB_job_data_files/results', 'wandb': '/content/drive/MyDrive/AB_job_data_files/wandb', 't5-small-work-arrangement-finetuned': '/content/drive/MyDrive/AB_job_data_files/t5-small-work-arrangement-finetuned', 'model_save': '/content/drive/MyDrive/AB_job_data_files/model_save', 'T5-small-non-fine-tuned-workarrangements_dev.csv': '/content/drive/MyDrive/AB_job_data_files/T5-small-non-fine-tuned-workarrangements_dev.csv', 'T5-small-non-fine-tuned-workarrangements_test.csv': '/content/drive/MyDrive/AB_job_data_files/T5-small-non-fine-tuned-workarrangements_test.csv'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def work_arrang(job_ad):\n",
        "\n",
        "    # Format the prompt\n",
        "    prompt = f\"Classify the work arrangement of the following job ad as one of the following: on-site, Remote, or Hybrid: {job_ad}\"\n",
        "\n",
        "    # Tokenize\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors='pt', truncation=True).to(device)\n",
        "\n",
        "    # Generate output\n",
        "    job_ids = model.generate(input_ids, max_length=50, num_beams=4, early_stopping=True)\n",
        "\n",
        "    # Decode and return\n",
        "    return tokenizer.decode(job_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "j3CeZm2871IE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEV set\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Read the development set\n",
        "work_arrangement_dev = pd.read_csv(file_location['work_arrangements_development_set.csv'])\n",
        "\n",
        "# Lists to hold predictions and true labels\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "correct = 0\n",
        "\n",
        "# Prediction loop\n",
        "for index, row in work_arrangement_dev.iterrows():\n",
        "    predicted_label = work_arrang(row['job_ad'])\n",
        "\n",
        "    if predicted_label == \"on-site\":\n",
        "        predicted_label = \"OnSite\"\n",
        "\n",
        "    true_label = row['y_true']\n",
        "    match = predicted_label == true_label\n",
        "\n",
        "    # Append the prediction and true label\n",
        "    y_pred.append(predicted_label)\n",
        "    y_true.append(true_label)\n",
        "\n",
        "    # Print individual results\n",
        "    print(predicted_label, '----', true_label)\n",
        "    print(match)\n",
        "\n",
        "    if match:\n",
        "        correct += 1\n",
        "\n",
        "# Calculate and print overall accuracy\n",
        "total = len(work_arrangement_dev)\n",
        "accuracy = correct / total\n",
        "print(f\"count: {total}\")\n",
        "print(f\"correctly identified: {correct}\")\n",
        "print(f\"accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knvu7ELr8LXy",
        "outputId": "a4376680-9f8c-4e7f-9788-377c7b307e8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Remote ---- Remote\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "Remote ---- Hybrid\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- OnSite\n",
            "False\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- OnSite\n",
            "False\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Hybrid\n",
            "False\n",
            "Remote ---- OnSite\n",
            "False\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "Remote ---- OnSite\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "Remote ---- OnSite\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "Remote ---- OnSite\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- Remote\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- Remote\n",
            "False\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "OnSite ---- OnSite\n",
            "True\n",
            "Remote ---- Remote\n",
            "True\n",
            "OnSite ---- Hybrid\n",
            "False\n",
            "Remote ---- Hybrid\n",
            "False\n",
            "count: 99\n",
            "correctly identified: 57\n",
            "accuracy: 0.5757575757575758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TEST set\n",
        "\n",
        "\n",
        "# Read the development set\n",
        "work_arrangement_test = pd.read_csv(file_location['work_arrangements_test_set.csv'])\n",
        "\n",
        "# Lists to hold predictions and true labels\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "correct = 0\n",
        "\n",
        "# Prediction loop\n",
        "for index, row in work_arrangement_test.iterrows():\n",
        "    predicted_label = work_arrang(row['job_ad'])\n",
        "\n",
        "    if predicted_label == \"on-site\":\n",
        "        predicted_label = \"OnSite\"\n",
        "\n",
        "    true_label = row['y_true']\n",
        "    match = predicted_label == true_label\n",
        "\n",
        "    # Append the prediction and true label\n",
        "    y_pred.append(predicted_label)\n",
        "    y_true.append(true_label)\n",
        "\n",
        "    # Print individual results\n",
        "    #print(predicted_label, '----', true_label)\n",
        "    #print(match)\n",
        "\n",
        "    if match:\n",
        "        correct += 1\n",
        "\n",
        "# Calculate and print overall accuracy\n",
        "total = len(work_arrangement_dev)\n",
        "accuracy = correct / total\n",
        "print(f\"count: {total}\")\n",
        "print(f\"correctly identified: {correct}\")\n",
        "print(f\"accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNiXmPk1ln_K",
        "outputId": "9760074f-07af-4e8a-cdbc-883938fd5183"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 99\n",
            "correctly identified: 54\n",
            "accuracy: 0.5454545454545454\n"
          ]
        }
      ]
    }
  ]
}